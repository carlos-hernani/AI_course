---
title: "Advanced R"
author: "Carlos Hernani Morales"
date: "2025-03-23"
output: 
  html_document:
    toc: true
    toc_float: 
      collapsed: false

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# The pacman package is an R package management tool https://trinker.github.io/pacman/vignettes/Introduction_to_pacman.html
if (!require("pacman")) install.packages("pacman")
needed_packages <- c("glue", "dplyr", "tidyverse", "babynames", "skimr", "dslabs", "rstatix")
# Loads and install packages
pacman::p_load(needed_packages,character.only=TRUE)
```



__TIPS__: hover the mouse arrow over a function and press F1 to show the Help (or use the Help Tab)

__TIPS__: don't bother learning every function you encounter here, try to develop the skill of breaking down a problem into smaller ones and solve them individually. 

__TIPS__: R has clear advantage in fields like bio-statistics (and statistics in general), plotting (thanks to ggplot) and reporting. So if you have to take something from R, might just be that. You can use Python code from R using library reticulate.



The previous lesson taught you how to store data in R objects such as lists, matrices, etc. . What to do with those is the topic of this lesson.


# 1. Flow Control

Flow control allows us to decide what to do with our data if a condition (or conditions) is met (or not). Let's just say you have a dataset with travelers data and you want to exclude all the non-adults from the dataset. To be able to do that you have to filter all the data instances where the condition of age is below a certain value (e.g. 18). 
Another example would be you have a list of file names that you would like to load into a script, instead of loading them one by one you can loop through the list to load them.
These are example of why Flow Control is useful. 


## 1.1 Conditional Statements

### if else

Base R has the basic if-else statement.

```{r}
# Base R oneliner if-else statement
if (TRUE) "the action of the TRUE statement"
if (FALSE) "the action of the TRUE statement" else "the action of the FALSE statement"
```

### Boolean Logic

Before going any further we have to review some logic, specifically boolean logic. Boolean logic refers to the field of algebra that studies logical operators to determine if an statement is true or false. Logical operators are just symbols that act upon the statements, e.g. true_statement AND false_statement

The basic boolean operators are AND, OR, NOT. There are more but with these you can do anything boolean related (in fact only with {AND, NOT} you can do anything, but OR comes in handy; functionally complete set)

  + AND: (A AND B) only will be T (truth) if (both) A and B are truth. (also A & B)
  + OR: (A OR B) only will be T (truth) if A or B are truth. (also A | B)
  + NOT: (NOT A) negates A, so if A is originally T then NOT A = False (also !A)

Programming languages have also other operators for comparison like:

  + Equal: ==
  + Not Equal : != 
  + Greater than: >
  + Less than: <

etc, etc.

For example we could ask what Star Wars characters are male and have blond hair. We will see all these functions next, just focus on the logic

```{r}
starwars %>% subset(gender=="masculine" & hair_color=="blond")
```

### Exercise: Logical operators

Take the code from before and change code inside _subset()_ to:

  1. Take all the instances that have brown or black eyes.
  2. Take all the instances that have greater height than 100 and are not gender masculine.
  3. Take all the instances that have greater height than 100 and are not gender masculine and their world is Alderaan.

```{r}
starwars %>% subset()
starwars %>% subset()
starwars %>% subset()
```

### Vectorised if-else

Usually we work with vectors (lists, arrays, matrices, etc) so we want to be able to check an if-else statement for every element of the vector.
To apply this to an array of values we need a _vectorised if-else_, base R has _ifelse_.

```{r}
# array of car speeds in the city; 
speed <- sample.int(80, 10)
ifelse(speed>=50, glue("Will be fined. Speed {as.character(speed)} km/h"), glue("Will Not be fined. Speed {as.character(speed)} km/h"))
```

Typically real-world datasets have NAs present (be it because there was an error while imputing the values or because people are lazy) 
If NAs are present Base R ifelse is not useful.

```{r}
speed <- c("29", NA)
ifelse(speed>=50, glue("Will be fined. Speed {as.character(speed)} km/h"), glue("Will Not be fined. Speed {as.character(speed)} km/h"))
```

To check multiple conditions (and do different actions) we can use:

```{r}
# Base R if; else if and else statements
# kind of tiring; see dplyr::case_when
grade <- 90
if (grade >= 90){
  "A"
}else if (x > 80){
    "B"
}else if (x > 50){
    "C"
}else{
    "F"
  }
```

If instead we have a set of values that our variable can have and we want to check it or do an action for each case, we have the _switch_ statement.

```{r}
grade <- "F"
switch(grade,
       A = "great job",
       B = "good job",
       C = "ok job",
       F = "try harder next time",
       stop("Unexpected value.")
       )
```

For a more general (vectorised) and _tidier_ code we can use *dplyr 's case_when and case_match*  (more on that next lesson).
(https://dplyr.tidyverse.org/reference/case_when.html  ;  https://dplyr.tidyverse.org/reference/case_match.html)

It is fine to use Base R but you will soon realize that the tidyverse way of doing things is easier and once you learn the basics it will boost your performance.

```{r}
# if_else can handle NA
if_else(speed>=50, glue("Will be fined. Speed {as.character(speed)} km/h"), glue("Will Not be fined. Speed {as.character(speed)} km/h"), missing = "missing velocity")
```


```{r}
# case_when allows vectorised input and multiple conditions
x <- 1:10
dplyr::case_when(
  x %% 35 == 0 ~ "fizz buzz",
  x %% 5 == 0 ~ "fizz",
  x %% 7 == 0 ~ "buzz",
  is.na(x) ~ "???",
  .default =  as.character(x)
)
#>  [1] "1"    "2"    "3"    "4"    "fizz" "6"    "buzz" "8"    "9"    "fizz"
```

```{r}
# case_match is a vectorised switch
notes <- c("Do", "Re", "Mi", "Fa", "Sol", "La", "Si", "Sib")

dplyr::case_match(notes,
                  "Do"~ "C",
                  "Re"~ "D", 
                  "Mi"~ "E", 
                  "Fa"~ "F", 
                  "Sol"~ "G", 
                  "La"~ "A", 
                  "Si"~ "B",
                  #.default = "outside the written possibilities; use default to handle it"
                  )
```


Case_when (case_match) are usually used inside tidyverse's _mutate_ to create (or modify) columns inside a dataframe.

### Exercise: multiple courses of action using tidyverse

Use the starwars dataset to create a column named "message" with a message that will be either "You are taller than 50% of people" "You are shorter than 50% of people". Be careful of NAs.

```{r}
# starwars %>% mutate(
#   message = case_when(
# 
#   )

```



## 1.2. Loops

Loops are used to do a series of task in a sequence, _for_ is used to iterate over items in an array, _while_ performs an action (indefinitely) until a condition is met and _repeat_ does the same but to stop it you have to use _break_. In a data science context, the most common tool is using _map_, _apply_ (more on that in Functions) and _for_ .

```{r}
i <- "Check this"
print(glue("i has an initial value: {i}"))
for (i in 1:10) {
  print(i**2)
}
print(glue("i has a final value {i}")) # for loop item overwrites
```

To control the iteration you can use _next_ or _break_:

```{r}
# list of passengers with the possibility of an infected contagious person, 
possibilities <- c("OK", "Mildly Contagious", "Extremely Contagious")
passengers_status <- sample(possibilities, 100, replace = TRUE, prob=c(90,9,1)) # 10 percent infected
for (status in passengers_status) {
  if (status == "OK") next # go to next iteration
  if (status == "Mildly Contagious"){
    print("Get out of the plane")
  }
  if (status == "Extremely Contagious"){
    print("Trip cancelled")
    break # stops the loop
  }
}
table(passengers_status)
```

### Exercise: Loops & ChatGPT


Instead of using Google this time now learn to use ChatGPT. LLMs (Large Language Models) are changing the way people orient their workflow. But coding remains an engineering problem, break a big problem into smaller ones, studies show that LLMs work best when they are prompted with very precise inputs and tasks, so:

  + Give ChatGPT a big prompt such as: "In R: You are given a numeric vector 'heights', where each element represent the height of basketball players in a fixed sequence. The task is to construct a new numeric vector 'taller_count' of the same length where each element at index 'i' represents how many taller players there are after the player at that position. Only use 'for' loops."
  + (The MOST IMPORTANT STEP) Try to understand the code ChatGPT has given you. The better you code the better prompts you can give to LLMs. If you let GPT do all the work you won't develop problem solving skills.
  + When the code you are given fails, argue with ChatGPT to solve it, giving more precise information/mini-tasks. Provide it with the Error information.

  + Repeat this x5: you can ask ChatGPT for something like "Give me 'for' loop (in base R) examples that fail at execution or that produce incorrect results".
  
LLMs can give you: 

|                        | Correct Task                                | Incorrect Task                               |
|------------------------|---------------------------------------------|----------------------------------------------|
| Executes efficiently   | Best (No further changes)                   | Big problem if you don't understand the code |
| Executes inefficiently | Could be improved knowing about coding      | Same as before                               |
| Does not execute       | Not that bad (makes you aware of a problem) | At least it doesn't run                      |

Understanding the code is possibly the most important step of this. If the task (the algorithm implemented) is not the one you want you will get in the worst case scenario an apparently good code but it harm your work.

__TIPS__: Let's be honest most of you have already used some kind of LLM or other so, instead of banning it, let's try to learn how to use them correctly. From now on all the exercises questions will be done using ChatGPT and you will have to correct them.

```{r}

```


# 2. Functions

To avoid repeating code we can use functions and then apply them when needed.

The syntax is:

```{r}
name_of_function <- function(argument1, argument2){
  # The body of the function
  # Comment inside function; try to document what the function does or at least use names that are self-explanatory
  # to return a value just write the expression or use return()
  argument1 + argument2
  #return(argument1 + argument2)
}

name_of_function(10,10)

```

Usually you will give a name to your functions to re-utilize them later but sometimes when dealing with other functions that use a function as an input is better (if the code is short) to just use _anonymous functions_. When possible use this approach instead of _for_ loops (they can be slow if not used properly)

```{r}
# lapply applies a function over a list/vector
lapply(1:10, function(x) sqrt(2*x)) # returns a list of the same length of the input
sapply(1:10, function(x) sqrt(2*x)) # same values, but a vector
purrr::map(1:10, \(x) sqrt(2*x)) # From R 4.1; lambda-like functions can be done like this; map works the same as lapply but can handle tidyverse helpers
```

Functions should do a task (efficiently preferably), to do more complex task one could encapsulate them inside others or _pipe_ them into the next one.

_Pipes_  are operators that take the object from the left of the pipe and feeds it as an input to the right side of the pipe. To showcase this we will use some Regex examples (Regular expressions; string manipulation). There are at least 2 _pipes_: tidyverse (%>%) and Base R (|>). Tidyverse one can use a placeholder for the argument (.) .

```{r}
# 'fruit' contains the name of 80 fruits
#fruit |> str_view("berry") # This is equivalent to str_view(fruit, "berry")
#fruit %>% str_view("berry")
"berry" %>% str_view(fruit,.) # placeholder of tidyverse's pipe
```

Functions have their own environment so be mindful when assigning variables.

```{r}
var <- 33
foo <- function(){
  print(var) # the function can access the environment where the function is defined but not the other way around
  # foo has its own environment
  var <- 10 # var from inside of a function is not the same var outside the function
  var
}
print(var)
foo()
```

### Exercises: Functions and ChatGPT

Try to translate the code into a sentence (prompt) and ask ChatGPT to solve it. (You could also Copy/Paste the code but then you wouldn't be doing any skill development)

```{r}
# Given data frame
df <- data.frame(
  A = c(1, 2, 3),
  B = c(4, 5, 6),
  C = c(7, 8, 9)
)

df # take a look at df, 

# Using apply() to calculate row-wise sum
row_sums_apply <- apply(df, 2, sum) 
print("Row sums using apply:")
print(row_sums_apply)

# Using sapply() 
row_sums_sapply <- sapply(df, sum)
print("Row sums using sapply:")
print(row_sums_sapply)

```

This code was provided by ChatGPT, the idea is to: given a numeric vector calculate sum of numbers greater than the threshold. Uncomment the code and run it.

  + First, fix the problem (it won't run).
  + Second, make it more compact and use one of the functions from the "Conditional Statements" section.

```{r}
# Given vector of numbers
numbers <- c(1, 5, 8, 12, 3, 7, 10)

# Threshold value
threshold <- 6

# Using sapply() to calculate sum of numbers greater than the threshold
sum_result_sapply <- sapply(numbers, function(x) {
  if (x > threshold) {
    return(x)
  }
})

# Summing the result. 
# Uncomment section below
# total_sum_sapply <- sum(sum_result_sapply, na.rm = TRUE)
# 
# print(paste("Sum of numbers greater than", threshold, "is:", total_sum_sapply))

```




# 3. Dataframes

A dataframe is a table, usually with column identifiers (column names) and sometimes with row identifiers (indexes). Let's see the iris dataset:



```{r}
#iris
dim(iris) # number of rows x number of columns
length(iris) # the number of columns
nrow(iris) # the number of rows
ncol(iris) # the number of columns
colnames(iris) # self-explanatory
rownames(iris) # this dataset doesn't have specific row names so just a number
head(iris) # first few rows
tail(iris) # last few rows
str(iris) # structure of dataframe, dims and classes
summary(iris) # summary statistics
View(iris) # opens a new window with the dataset
```
## Summary info of a dataframe

Base R has plenty of functions to get information from a dataset, like _summary_.

```{r}
summary(iris)
```

Or use _skim_ from the library _skimr_; _skim_ returns a dataframe with a tidier description of each variable. 

```{r}
skim(iris)
```



## Creating a dataframe from scratch

To create a dataframe (not very common; you probably won't do this ever, just load a dataset using _readr_) one can use Base R _data.frame_ or tidyverse's _tibble_:

```{r}
my_df <- data.frame(
  "Date_ymd" = c("2025/3/26", "2025/3/27"),
  "Class" = c("Advanced R", "Data Manipulation with Python"),
  "Teacher" = "Carlos H." # Data frame creation recycles data when the vectors in each column are not the same length.
)
my_df
class(my_df)
```
## Creating new columns and rows

To create new columns, there is a straightforward way with '$', '[]' or with '[[]]'.

```{r}
my_df$new_col <- 1
my_df[["new_col2"]] <- 2
my_df["new_col3"] <- 3
my_df
```

Dataframes can also be concatenated with other dataframes using _cbind_ or _rbind_ (columns and rows).

### Mini-Exercise: Concatenation

```{r}
# create a row and a column and bind them to 'my_df' using cbind and rbind
```

## Changing the names of columns

To change the column names.

```{r}
colnames(my_df)[3] <- "Professor"
my_df
```




## Accesing data inside a dataframe: Slicing

To access columns (or rows) in the dataframe we can use '[]', '[[]]' or '$' ('$' only for the columns) (the difference is the type of output, check with _class()_):

```{r}
my_df["Class"]
#class(my_df["Class"]) # a dataframe
my_df$Class
#class(my_df$Class) # a vector
my_df[["Class"]]
#class(my_df[["Class"]]) # a vector
```

To further access information in a dataframe you will have to add the index (or indexes):

```{r}
iris[1:5, c("Species", "Sepal.Length")]
iris[1:5, 1:2] # dataframe[row_slice, column_slice]
iris[1:5,] # if there is no value before or after the comma, it takes the whole range of values possible for that field (row/col)
```

### Slicing by condition

There is also the possibility of slicing a dataset using conditions using '[]'. We will see more after "Loading a dataset".

```{r}
iris[iris$Species == "setosa",]
```




## Loading a dataset

As I commented before, most of the time you will not create a dataframe manually. You will download a dataset (an csv, excel, etc) and load it into your code.

There is a folder called _datasets_ in the github repo. My best advice is that if possible don't bother writing the code for the loading: 

  1. Go to the Files Tab on the bottom-right part of RStudio.
  2. Go to the folder (datasets) where the dataset is stored.
  3. Left-click it and click "Import Dataset...".
  4. A new window will pop up. There are several options, like to trim the whitespaces from character fields, avoid NAs, skip rows, select the type of column ,etc.
  5. Once you have tinkered with the options to load your data. Copy the code from the "Code Preview" field and paste it into the code.


```{r}
library(readr)
olive_original <- read_csv("datasets/olive_original.csv")
olive_original
```

Once the dataset is loaded into a dataframe is recommended to use _summary_ or _skim_ to see the statistical information.

```{r}
skim(olive_original)
```



## Accesing data inside a dataframe: Conditional slicing with subset()

Aside from the usual '[]', '[[]]' or '$', we can use _subset_ to get a chunk of interest (that meet some conditions) from our dataframe. Let's say we want only the olive oil from southern Italy and with an oleic concentration higher than the median value (the top 50%).

```{r}
median(olive_original$oleic)
olive_original %>% subset(region == "Southern Italy" & oleic < median(oleic))
```

Be careful when subsetting with conditions as you will have to be precise in what you need. For example, in the example I gave before I wasn't very precise. What I did is get all the Southern Italy oil with a higher value than the median over the whole dataset. If I wanted only the top 50% of oleic acid on the Southern oil I can do:

```{r}
olive_original %>% subset(region == "Southern Italy") %>% subset(oleic < median(oleic)) 
```

To select one or more columns (or exclude) we can use the 'select' option inside _subset_ or use dplyr's _select_ function:

```{r}
olive_original %>% subset(region == "Southern Italy") %>% subset(oleic < median(oleic), select=-region) # base R with dplyr pipe; 
olive_original %>% subset(region == "Southern Italy") %>% subset(oleic < median(oleic)) %>% select(-region) #dplyr
```

Writing code using _subset_ is cleaner and easier to do. So focus on learning well how to use it.




## Saving a dataframe into a file.

In our case we will save it to a .csv file but there are more types (tsv, excel, etc)

```{r}
data("olive")
write_csv(olive, "./datasets/olive_original.csv")
```

## Dataframe Exercise

  + Download a tabular dataset from the internet (I will be using https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset)

  + Import it like we did before.
  
  + Show some statistical information.
  
  + Add a column with random values. There is a function in Base R to add noise to a vector. Look it up.
  
  + Save the modified dataframe into another file for later .
  
  + Apply a Mann-Whitney U test to check if the there is association between each column to the Outcome column. (The code is below)
  
  + Use the information of the test to drop the columns that are not significant. 
  
  
  
```{r}

```
  

# 4. Plotting Base R

R has very good plotting in its Base programming, but, as you will see in the next class, ggplot is better.

Plotting has a lot of different options so I won't be able to teach all of them in just one class but you can visit https://r-graph-gallery.com/base-R.html to see Base R plotting examples.

That web is also good to learn what is possible with ggplot.


Useful parameters:

  + Titles
  + Legends
  + Annotations
  + Adding straight lines (e.g. mean)
  + Scaling the axis
  + Customize tick marks
  + Plotting symbols
  + Line Types
  + Colors


### plot() example and Exercise

As you can see there are a lot of parameters/options and kinds of plots. The tasks are the following:

Using the mtcars dataset.

```{r}
head(mtcars)
```


  + Scatter Plot of Miles per Gallon vs. Horsepower
Create a scatter plot showing the relationship between Miles per Gallon (mpg) and Horsepower (hp). Customize the plot with a title and axis labels. Use blue color and solid circles for the points.

  + Boxplot of Miles per Gallon by Number of Cylinders
Create a boxplot comparing Miles per Gallon (mpg) for cars with different numbers of cylinders (cyl). Add a title and axis labels. Color the boxes light green.

  + Histogram of Miles per Gallon
Create a histogram that shows the distribution of Miles per Gallon (mpg) across the cars in the dataset. Customize the plot with a title, axis labels, orange-colored bars, and black borders. Set the number of bins to 10.

  + Bar Plot of Frequency of Different Numbers of Cylinders
Create a bar plot that shows the frequency of cars with different numbers of cylinders (cyl). Add appropriate axis labels and color the bars purple.

  + Correlation Heatmap of All Numeric Variables
Create a heatmap that visualizes the correlation matrix of all numeric variables in the mtcars dataset. Use an appropriate color scale (e.g., heat.colors()) and ensure the heatmap is clearly labeled.

```{r}
plot(x = 1:10,                         # x-coordinates
     y = 1:10,                         # y-coordinates
     type = "p",                       # Just draw points (no lines)
     main = "Plot example",          
     sub = "The subtitle",
     xlab = "This is the x-axis label",
     ylab = "This is the y-axis label",
     xlim = c(0, 11),                  # Min and max values for x-axis
     ylim = c(0, 11),                  # Min and max values for y-axis
     col = "blue",                     # Color of the points
     pch = 16,                         # Type of symbol (16 means Filled circle)
     cex = 1)                           # Size of the symbols
```

```{r}
# Scatter plot: mpg vs hp
plot(mtcars$mpg, mtcars$hp,
     main = "Scatter Plot of MPG vs Horsepower",
     xlab = "Miles Per Gallon (mpg)",
     ylab = "Horsepower (hp)",
     pch = 19,  # solid circles
     col = "blue")

```


```{r}
# Boxplot: mpg by cyl (number of cylinders)
boxplot(mpg ~ cyl, data = mtcars,
        main = "Boxplot of MPG by Number of Cylinders",
        xlab = "Number of Cylinders (cyl)",
        ylab = "Miles Per Gallon (mpg)",
        col = "lightgreen")

```

```{r}
# Histogram of mpg (Miles per Gallon)
hist(mtcars$mpg,
     main = "Histogram of Miles Per Gallon",
     xlab = "Miles Per Gallon (mpg)",
     col = "orange",
     border = "black",
     breaks = 10)  # Set number of bins

```


```{r}
# Bar plot: Frequency of different numbers of cylinders
barplot(table(mtcars$cyl),
        main = "Bar Plot of Number of Cylinders",
        xlab = "Number of Cylinders",
        ylab = "Frequency",
        col = "purple")

```



```{r}
# Correlation plot of numeric variables; 
cor_matrix <- cor(mtcars)
# Use heatmap to display correlation matrix
heatmap(cor_matrix,
        main = "Correlation Heatmap of mtcars",
        col = heat.colors(10),  # Color palette for heatmap
        scale = "none")

```













