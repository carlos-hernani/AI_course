---
title: "Advanced R"
author: "Carlos Hernani Morales"
date: "2025-03-23"
output: 
  html_document:
    toc: true
    toc_float: 
      collapsed: false

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# The pacman package is an R package management tool https://trinker.github.io/pacman/vignettes/Introduction_to_pacman.html
if (!require("pacman")) install.packages("pacman")
needed_packages <- c("glue", "dplyr", "tidyverse", "babynames", "skimr", "dslabs", "rstatix")
# Loads and install packages
pacman::p_load(needed_packages,character.only=TRUE)
```



__TIPS__: hover the mouse arrow over a function and press F1 to show the Help (or use the Help Tab)

__TIPS__: don't bother learning every function you encounter here, try to develop the skill of breaking down a problem into smaller ones and solve them individually. 

__TIPS__: R has clear advantage in fields like bio-statistics (and statistics in general), plotting (thanks to ggplot) and reporting. So if you have to take something from R, might just be that. You can use Python code from R using library reticulate.



The previous lesson taught you how to store data in R objects such as lists, matrices, etc. . What to do with those is the topic of this lesson.


# 1. Flow Control

Flow control allows us to decide what to do with our data if a condition (or conditions) is met (or not). Let's just say you have a dataset with travelers data and you want to exclude all the non-adults from the dataset. To be able to do that you have to filter all the data instances where the condition of age is below a certain value (e.g. 18). 
Another example would be you have a list of file names that you would like to load into a script, instead of loading them one by one you can loop through the list to load them.
These are example of why Flow Control is useful. 


## 1.1 Conditional Statements

### if else

Base R has the basic if-else statement.

```{r}
# Base R oneliner if-else statement
if (TRUE) "the action of the TRUE statement"
if (FALSE) "the action of the TRUE statement" else "the action of the FALSE statement"
```

### Boolean Logic

Before going any further we have to review some logic, specifically boolean logic. Boolean logic refers to the field of algebra that studies logical operators to determine if an statement is true or false. Logical operators are just symbols that act upon the statements, e.g. true_statement AND false_statement

The basic boolean operators are AND, OR, NOT. There are more but with these you can do anything boolean related (in fact only with {AND, NOT} you can do anything, but OR comes in handy; functionally complete set)

  + AND: (A AND B) only will be T (truth) if (both) A and B are truth. (also A & B)
  + OR: (A OR B) only will be T (truth) if A or B are truth. (also A | B)
  + NOT: (NOT A) negates A, so if A is originally T then NOT A = False (also !A)

Programming languages have also other operators for comparison like:

  + Equal: ==
  + Not Equal : != 
  + Greater than: >
  + Less than: <

etc, etc.

For example we could ask what Star Wars characters are male and have blond hair. We will see all these functions next, just focus on the logic

```{r}
starwars %>% subset(gender=="masculine" & hair_color=="blond")
```

### Exercise: Logical operators

Take the code from before and change code inside _subset()_ to:

  1. Take all the instances that have brown or black eyes.
  2. Take all the instances that have greater height than 100 and are not gender masculine.
  3. Take all the instances that have greater height than 100 and are not gender masculine and their world is Alderaan.

```{r}
starwars %>% subset()
starwars %>% subset()
starwars %>% subset()
```

### Vectorised if-else

Usually we work with vectors (lists, arrays, matrices, etc) so we want to be able to check an if-else statement for every element of the vector.
To apply this to an array of values we need a _vectorised if-else_, base R has _ifelse_.

```{r}
# array of car speeds in the city; 
speed <- sample.int(80, 10)
ifelse(speed>=50, glue("Will be fined. Speed {as.character(speed)} km/h"), glue("Will Not be fined. Speed {as.character(speed)} km/h"))
```

Typically real-world datasets have NAs present (be it because there was an error while imputing the values or because people are lazy) 
If NAs are present Base R ifelse is not useful.

```{r}
speed <- c("29", NA)
ifelse(speed>=50, glue("Will be fined. Speed {as.character(speed)} km/h"), glue("Will Not be fined. Speed {as.character(speed)} km/h"))
```

To check multiple conditions (and do different actions) we can use:

```{r}
# Base R if; else if and else statements
# kind of tiring; see dplyr::case_when
grade <- 90
if (grade >= 90){
  "A"
}else if (x > 80){
    "B"
}else if (x > 50){
    "C"
}else{
    "F"
  }
```

If instead we have a set of values that our variable can have and we want to check it or do an action for each case, we have the _switch_ statement.

```{r}
grade <- "F"
switch(grade,
       A = "great job",
       B = "good job",
       C = "ok job",
       F = "try harder next time",
       stop("Unexpected value.")
       )
```

For a more general (vectorised) and _tidier_ code we can use *dplyr 's case_when and case_match*  (more on that next lesson).
(https://dplyr.tidyverse.org/reference/case_when.html  ;  https://dplyr.tidyverse.org/reference/case_match.html)

It is fine to use Base R but you will soon realize that the tidyverse way of doing things is easier and once you learn the basics it will boost your performance.

```{r}
# if_else can handle NA
if_else(speed>=50, glue("Will be fined. Speed {as.character(speed)} km/h"), glue("Will Not be fined. Speed {as.character(speed)} km/h"), missing = "missing velocity")
```


```{r}
# case_when allows vectorised input and multiple conditions
x <- 1:10
dplyr::case_when(
  x %% 35 == 0 ~ "fizz buzz",
  x %% 5 == 0 ~ "fizz",
  x %% 7 == 0 ~ "buzz",
  is.na(x) ~ "???",
  .default =  as.character(x)
)
#>  [1] "1"    "2"    "3"    "4"    "fizz" "6"    "buzz" "8"    "9"    "fizz"
```

```{r}
# case_match is a vectorised switch
notes <- c("Do", "Re", "Mi", "Fa", "Sol", "La", "Si", "Sib")

dplyr::case_match(notes,
                  "Do"~ "C",
                  "Re"~ "D", 
                  "Mi"~ "E", 
                  "Fa"~ "F", 
                  "Sol"~ "G", 
                  "La"~ "A", 
                  "Si"~ "B",
                  #.default = "outside the written possibilities; use default to handle it"
                  )
```


Case_when (case_match) are usually used inside tidyverse's _mutate_ to create (or modify) columns inside a dataframe.

### Exercise: multiple courses of action using tidyverse

Use the starwars dataset to create a column named "message" with a message that will be either "You are taller than 50% of people" "You are shorter than 50% of people". Be careful of NAs.

```{r}
starwars %>% mutate(
  message = case_when(
    height < median(height, na.rm=TRUE) ~ "You are taller than 50% of people", 
    height >= median(height, na.rm=TRUE) ~ "You are shorter than 50% of people", 
    T ~ "no available data")
  )

```



## 1.2. Loops

Loops are used to do a series of task in a sequence, _for_ is used to iterate over items in an array, _while_ performs an action (indefinitely) until a condition is met and _repeat_ does the same but to stop it you have to use _break_. In a data science context, the most common tool is using _map_, _apply_ (more on that in Functions) and _for_ .

```{r}
i <- "Check this"
print(glue("i has an initial value {i}"))
for (i in 1:10) {
  print(i**2)
}
print(glue("i has a final value {i}")) # for loop item overwrites
```

To control the iteration you can use _next_ or _break_:

```{r}
# list of passengers with the possibility of an infected contagious person, 
possibilities <- c("OK", "Mildly Contagious", "Extremely Contagious")
passengers_status <- sample(possibilities, 100, replace = TRUE, prob=c(90,9,1)) # 10 percent infected
for (status in passengers_status) {
  if (status == "OK") next # go to next iteration
  if (status == "Mildly Contagious"){
    print("Get out of the plane")
  }
  if (status == "Extremely Contagious"){
    print("Trip cancelled")
    break # stops the loop
  }
}
table(passengers_status)
```


# 2. Functions

To avoid repeating code we can use functions and then apply them when needed.

The syntax is:

```{r}
name_of_function <- function(argument1, argument2){
  # The body of the function
  # Comment inside function; try to document what the function does or at least use names that are self-explanatory
  # to return a value just write the expression or use return()
  argument1 + argument2
  #return(argument1 + argument2)
}

name_of_function(10,10)

```

Usually you will give a name to your functions to re-utilize them later but sometimes when dealing with other functions that use a function as an input is better (if the code is short) to just use _anonymous functions_. When possible use this approach instead of _for_ loops (they can be slow if not used properly)

```{r}
# lapply applies a function over a list/vector
lapply(1:10, function(x) sqrt(2*x)) # returns a list of the same length of the input
sapply(1:10, function(x) sqrt(2*x)) # same values, but a vector
purrr::map(1:10, \(x) sqrt(2*x)) # From R 4.1; lambda-like functions can be done like this; map works the same as lapply but can handle tidyverse helpers
```

Functions should do a task (efficiently preferably), to do more complex task one could encapsulate them inside others or _pipe_ them into the next one.

_Pipes_  are operators that take the object from the left of the pipe and feeds it as an input to the right side of the pipe. To showcase this we will use some Regex examples (Regular expressions; string manipulation). There are at least 2 _pipes_: tidyverse (%>%) and Base R (|>). Tidyverse one can use a placeholder for the argument (.) .

```{r}
# 'fruit' contains the name of 80 fruits
#fruit |> str_view("berry") # This is equivalent to str_view(fruit, "berry")
#fruit %>% str_view("berry")
"berry" %>% str_view(fruit,.) # placeholder of tidyverse's pipe
```

Functions have their own environment so be mindful when assigning variables.

```{r}
var <- 33
foo <- function(){
  print(var) # the function can access the environment where the function is defined but not the other way around
  # foo has its own environment
  var <- 10 # var from inside of a function is not the same var outside the function
  var
}
print(var)
foo()
```


# 3. Dataframes

A dataframe is a table, usually with column identifiers (column names) and sometimes with row identifiers (indexes). Let's see the iris dataset:



```{r}
iris
dim(iris) # number of rows x number of columns
length(iris) # the number of columns
nrow(iris) # the number of rows
ncol(iris) # the number of columns
colnames(iris) # self-explanatory
rownames(iris) # this dataset doesn't have specific row names so just a number
head(iris) # first few rows
tail(iris) # last few rows
str(iris) # structure of dataframe, dims and classes
summary(iris) # summary statistics
View(iris) # opens a new window with the dataset
```
## Summary info of a dataframe

Base R has plenty of functions to get information from a dataset, like _summary_.

```{r}
summary(iris)
```

Or use _skim_ from the library _skimr_; _skim_ returns a dataframe with a tidier description of each variable. 

```{r}
skim(iris)
```



## Creating a dataframe from scratch

To create a dataframe (not very common; you probably won't do this ever, just load a dataset using _readr_) one can use Base R _data.frame_ or tidyverse's _tibble_:

```{r}
my_df <- data.frame(
  "Date_ymd" = c("2025/3/26", "2025/3/27"),
  "Class" = c("Advanced R", "Data Manipulation with Python"),
  "Teacher" = "Carlos H." # Data frame creation recycles data when the vectors in each column are not the same length.
)
my_df
class(my_df)
```
## Creating new columns and rows

To create new columns, there is a straightforward way with '$', '[]' or with '[[]]'.

```{r}
my_df$new_col <- 1
my_df[["new_col2"]] <- 2
my_df["new_col3"] <- 3
my_df
```

Dataframes can also be concatenated with other dataframes using _cbind_ or _rbind_ (columns and rows).

```{r}
# create a row and a column and bind them to 'my_df' using cbind and rbind
```

## Changing the names of columns

To change the column names.

```{r}
colnames(my_df)[3] <- "Professor"
my_df
```




## Accesing data inside a dataframe: Slicing

To access columns (or rows) in the dataframe we can use '[]', '[[]]' or '$' ('$' only for the columns) (the difference is the type of output, check with _class()_):

```{r}
my_df["Class"]
#class(my_df["Class"]) # a dataframe
my_df$Class
#class(my_df$Class) # a vector
my_df[["Class"]]
#class(my_df[["Class"]]) # a vector
```

To further access information in a dataframe you will have to add the index (or indexes):

```{r}
iris[1:5, c("Species", "Sepal.Length")]
iris[1:5, 1:2] # dataframe[row_slice, column_slice]
iris[1:5,] # if there is no value before or after the comma, it takes the whole range of values possible for that field (row/col)
```

### Slicing by condition

There is also the possibility of slicing a dataset using conditions using '[]'. We will see more after "Loading a dataset".

```{r}
iris[iris$Species == "setosa",]
```




## Loading a dataset

As I commented before, most of the time you will not create a dataframe manually. You will download a dataset (an csv, excel, etc) and load it into your code.

There is a folder called _datasets_ in the github repo. My best advice is that if possible don't bother writing the code for the loading: 

  1. Go to the Files Tab on the bottom-right part of RStudio.
  2. Go to the folder (datasets) where the dataset is stored.
  3. Left-click it and click "Import Dataset...".
  4. A new window will pop up. There are several options, like to trim the whitespaces from character fields, avoid NAs, skip rows, select the type of column ,etc.
  5. Once you have tinkered with the options to load your data. Copy the code from the "Code Preview" field and paste it into the code.


```{r}
library(readr)
olive_original <- read_csv("datasets/olive_original.csv")
olive_original
```

Once the dataset is loaded into a dataframe is recommended to use _summary_ or _skim_ to see the statistical information.

```{r}
skim(olive_original)
```



## Accesing data inside a dataframe: Conditional slicing with subset()

Aside from the usual '[]', '[[]]' or '$', we can use _subset_ to get a chunk of interest (that meet some conditions) from our dataframe. Let's say we want only the olive oil from southern Italy and with an oleic concentration higher than the median value (the top 50%).

```{r}
median(olive_original$oleic)
olive_original %>% subset(region == "Southern Italy" & oleic < median(oleic))
```

Be careful when subsetting with conditions as you will have to be precise in what you need. For example, in the example I gave before I wasn't very precise. What I did is get all the Southern Italy oil with a higher value than the median over the whole dataset. If I wanted only the top 50% of oleic acid on the Southern oil I can do:

```{r}
olive_original %>% subset(region == "Southern Italy") %>% subset(oleic < median(oleic)) 
```

To select one or more columns (or exclude) we can use the 'select' option inside _subset_ or use dplyr's _select_ function:

```{r}
olive_original %>% subset(region == "Southern Italy") %>% subset(oleic < median(oleic), select=-region) # base R with dplyr pipe; 
olive_original %>% subset(region == "Southern Italy") %>% subset(oleic < median(oleic)) %>% select(-region) #dplyr
```

Writing code using _subset_ is cleaner and easier to do. So focus on learning well how to use it.




## Saving a dataframe into a file.

In our case we will save it to a .csv file but there are more types (tsv, excel, etc)

```{r}
data("olive")
write_csv(olive, "./datasets/olive_original.csv")
```

## Dataframe Exercise

  + Download a tabular dataset from the internet (I will be using https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset)

  + Import it like we did before.
  
  + Show some statistical information.
  
  + Add a column with random values. There is a function in Base R to add noise to a vector. Look it up.
  
  + Save the modified dataframe into another file for later .
  
  + Apply a Mann-Whitney U test to check if the there is association between each column to the Outcome column. (The code is below)
  
  + Use the information of the test to drop the columns that are not significant. 
  
  
  
```{r}
diabetes <- read_csv("datasets/diabetes.csv")
skim(diabetes)

diabetes$random <- rep(0,nrow(diabetes)) %>% jitter()

write_csv(diabetes, "./datasets/diabetes_mod.csv")

mann_whitney <- function(column){
  # Mann Whitney U test is a non-parametric statistical test to check if a hypothesis is correct or not.
  # In the MWU test case, the hypothesis is that there is no difference between groups in terms of their target value (Outcome in diabetes dataset for example)
  # if the p-value obtained is less than 0.05 it is usually considered that there is a significant difference between groups.
  wilcox.test(column ~ diabetes$Outcome)$p.value < 0.05# return True or False
}

mann_whitney_results <- sapply(diabetes, mann_whitney) # returns a False/True
# columns where there are significant values
columns_to_preserve <- names(diabetes)[mann_whitney_results]

diabetes %>% subset(select=columns_to_preserve)
```
  

# 4. Plotting Base R

R has very good plotting in its Base programming, but, as you will see in the next class, ggplot is better.

Plotting has a lot of different options so I won't be able to teach all of them in just one class but you can visit https://r-graph-gallery.com/base-R.html to see Base R plotting examples.

That web is also good to learn what is possible with ggplot.


Useful parameters:

  + Titles
  + Legends
  + Annotations
  + Adding straight lines (e.g. mean)
  + Scaling the axis
  + Customize tick marks
  + Plotting symbols
  + Line Types
  + Colors


## plot() example
```{r}
plot(x = 1:10,                         # x-coordinates
     y = 1:10,                         # y-coordinates
     type = "p",                       # Just draw points (no lines)
     main = "The Title",          
     sub = "The subtitle",
     xlab = "This is the x-axis label",
     ylab = "This is the y-axis label",
     xlim = c(0, 11),                  # Min and max values for x-axis
     ylim = c(0, 11),                  # Min and max values for y-axis
     col = "blue",                     # Color of the points
     pch = 16,                         # Type of symbol (16 means Filled circle)
     cex = 1)                           # Size of the symbols
```
























